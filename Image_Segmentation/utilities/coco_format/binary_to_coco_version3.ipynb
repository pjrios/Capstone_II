{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95345cee",
   "metadata": {},
   "source": [
    "This code converts a set of binary masks of 256x256 size into COCO format annotations, which is a JSON file that stores the information about the objects in the images and the relationships between the images and objects. The binary masks are assumed to be stored in the 'masks' folder and are processed one by one. For each mask image, its contours are found and stored as a list of points in the 'segmentation' field of an annotation. The annotations also include information about the image size, object category, and object bounding box. The resulting annotations are saved in a JSON file called 'annotations.json'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6239353",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Processing images:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [00:00<00:00, 2313.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting to annotations551.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the path to the folder containing the masks\n",
    "mask_folder = 'C:\\\\Users\\\\path\\\\to\\\\masks\\\\forlder'\n",
    "# Load all of the masks in the folder\n",
    "mask_files = [f for f in os.listdir(mask_folder) if f.endswith('.jpg')]\n",
    "\n",
    "# Initialize the COCO format dataset\n",
    "coco_output = {\n",
    "    \"licenses\": [\n",
    "        {\n",
    "            \"name\": \"\", \n",
    "            \"id\": 0, \n",
    "            \"url\": \"\"\n",
    "        }\n",
    "    ],\n",
    "    \"info\": {\n",
    "        \"contributor\": \"\", \n",
    "        \"date_created\": \"\", \n",
    "        \"description\": \"\", \n",
    "        \"url\": \"\", \n",
    "        \"version\": \"\", \n",
    "        \"year\": \"\"\n",
    "    },\n",
    "    \"categories\": [\n",
    "        {\n",
    "            \"id\": 1, \n",
    "            \"name\": \"Solar_Panel\", \n",
    "            \"supercategory\": \"\"\n",
    "        }\n",
    "    ],\n",
    "    \"images\": [],\n",
    "    \"annotations\": []\n",
    "}\n",
    "\n",
    "image_id = 1\n",
    "annotation_id = 1\n",
    "\n",
    "print(\"--Processing images:\")\n",
    "# Iterate over all of the masks\n",
    "for i, mask_file in tqdm(enumerate(mask_files), total=len(mask_files)):\n",
    "    # Iterate over all of the masks, Load the mask image and convert it to binary format, Find the contours of the objects in the binary mask\n",
    "    mask = cv2.imread(os.path.join(mask_folder, mask_file), cv2.IMREAD_GRAYSCALE)\n",
    "    _, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find the contours of the objects in the binary mask\n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Get the base file name without the \"_label\" suffix\n",
    "    base_filename, _ = os.path.splitext(mask_file)\n",
    "    base_filename = base_filename.replace(\"_label\", \"\")\n",
    "    \n",
    "    # Store the image information\n",
    "    image = {\n",
    "        \"id\": image_id, \n",
    "        \"width\": 256,\n",
    "        \"height\": 256,\n",
    "        \"file_name\": f\"{base_filename}.jpg\",\n",
    "        \"license\": 0,\n",
    "        \"flickr_url\": \"\",\n",
    "        \"coco_url\": \"\",\n",
    "        \"date_captured\": 0\n",
    "    }\n",
    "    coco_output[\"images\"].append(image)\n",
    "    for j, contour in enumerate(contours):\n",
    "        contour = contour.flatten().tolist()\n",
    "        x = [point for point in contour[0::2]]\n",
    "        y = [point for point in contour[1::2]]\n",
    "        if len(x) < 2:\n",
    "            continue\n",
    "        segmentation = []\n",
    "        for i in range(len(x)):\n",
    "            segmentation.extend([x[i], y[i]])\n",
    "        annotation = {\n",
    "            \"id\": annotation_id,\n",
    "            \"image_id\": image_id,\n",
    "            \"category_id\": 1,\n",
    "            \"segmentation\": [segmentation],\n",
    "            \"bbox\": [min(x), min(y), max(x) - min(x), max(y) - min(y)],\n",
    "            \"iscrowd\": 0\n",
    "        }\n",
    "        coco_output[\"annotations\"].append(annotation)\n",
    "        #print(annotation)\n",
    "\n",
    "    image_id=image_id+1\n",
    "    annotation_id=annotation_id+1\n",
    "\n",
    "# Save the COCO format dataset to a JSON file\n",
    "print(\"Exporting to annotations551.json.\")\n",
    "with open('annotations551.json', 'w') as fp:\n",
    "    json.dump(coco_output, fp, indent=4, separators=(',', ': '))\n",
    "    #json.dump(coco_output, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4f44836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty or small segmentations: 2\n",
      "File name: PV01_325122_1203837.jpg\n",
      "File name: PV01_325122_1203837.jpg\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def find_empty_or_small_segmentations(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    empty_or_small_segmentations = []\n",
    "    for image in data[\"images\"]:\n",
    "        for annotation in data[\"annotations\"]:\n",
    "            if image[\"id\"] == annotation[\"image_id\"] and len(annotation[\"segmentation\"]) < 2:\n",
    "                empty_or_small_segmentations.append((image[\"file_name\"], annotation))\n",
    "\n",
    "    return empty_or_small_segmentations\n",
    "\n",
    "file_path = \"masks/annotations.json\"\n",
    "empty_or_small_segmentations = find_empty_or_small_segmentations(file_path)\n",
    "print(\"Number of empty or small segmentations:\", len(empty_or_small_segmentations))\n",
    "for file_name, annotation in empty_or_small_segmentations:\n",
    "    print(\"File name:\", file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0842ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d98bfe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
